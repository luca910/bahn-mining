{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import openpyxl\n",
    "import os\n",
    "os.makedirs('out', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel: Datenfilterfunktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daten von CSV in Data Frame extrahieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_as_data_x(file_path):\n",
    "    \"\"\"\n",
    "    Lädt eine CSV-Datei und gibt sie als DataFrame zurück.\n",
    "    Die relevanten Spaltennamen werden generalisiert:\n",
    "      - 'plannedArrival' oder 'plannedDeparture' -> 'planned'\n",
    "      - 'changedArrivalTime' oder 'changedDepartureTime' -> 'changed'\n",
    "      - 'arrival_delay' oder 'departure_delay' -> 'delay'\n",
    "    Zusätzlich werden alle negativen 'delay'-Werte auf 0 gesetzt.\n",
    "\n",
    "    :param file_path: Der Pfad zur CSV-Datei, die geladen werden soll.\n",
    "    :return: DataFrame mit generalisierten Spaltennamen und angepassten Werten.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # CSV-Datei einlesen, unter der Annahme, dass die Spalten durch Semikolon getrennt sind\n",
    "        df = pd.read_csv(file_path, sep=\";\", header=0)\n",
    "        \n",
    "        # Spaltenumbenennung basierend auf gemeinsamer Bedeutung\n",
    "        rename_mapping = {\n",
    "            'plannedArrival': 'planned',\n",
    "            'plannedDeparture': 'planned',\n",
    "            'changedArrivalTime': 'changed',\n",
    "            'changedDepartureTime': 'changed',\n",
    "            'arrival_delay': 'delay',\n",
    "            'departure_delay': 'delay'\n",
    "        }\n",
    "        \n",
    "        # Nur Spalten umbenennen, die tatsächlich in der CSV vorhanden sind\n",
    "        df.rename(columns={col: rename_mapping[col] for col in df.columns if col in rename_mapping}, inplace=True)\n",
    "        \n",
    "        # Falls die generalisierte Spalte 'delay' existiert, negative Werte auf 0 setzen\n",
    "        if 'delay' in df.columns:\n",
    "            df['delay'] = df['delay'].apply(lambda x: max(x, 0))\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        raise ValueError(f\"Die Datei unter dem Pfad {file_path} wurde nicht gefunden.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        raise ValueError(\"Die CSV-Datei ist leer.\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Fehler beim Einlesen der Datei: {e}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtert die Daten entsprechend auf Wunsch nach Bahnhof, Datum oder Woche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_x(data, evas=None, date=None, week_number=None):\n",
    "    \"\"\"\n",
    "    Filtert die Daten basierend auf den gegebenen Parametern.\n",
    "    \n",
    "    :param data: DataFrame mit den zugrunde liegenden Daten.\n",
    "    :param evas: Liste von EVA-Nummern der Bahnhöfe, nach denen gefiltert werden soll (Optional).\n",
    "    :param date: Das Datum, nach dem gefiltert werden soll (Optional, im Format 'YYYY-MM-DD').\n",
    "    :param week_number: Die Kalenderwoche, nach der gefiltert werden soll (Optional).\n",
    "    :return: Gefilterte Daten, die an die jeweilige Berechnungsfunktion übergeben werden können.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Überprüfen, ob die Daten vorhanden sind\n",
    "    if data.empty:\n",
    "        print(\"Es sind keine Daten vorhanden.\")\n",
    "        return None\n",
    "    \n",
    "    # Stelle sicher, dass die EVA-Spalte als String behandelt wird\n",
    "    data['eva'] = data['eva'].astype(str)\n",
    "    \n",
    "    # Wenn evas nicht spezifiziert, berücksichtige alle\n",
    "    if evas is not None:\n",
    "        # Falls nur ein einzelner Wert übergeben wurde, konvertiere ihn in eine Liste\n",
    "        if isinstance(evas, str):\n",
    "            evas = [evas]\n",
    "        \n",
    "        # Falls die übergebenen EVAs nicht in den Daten sind, gib eine Warnung aus\n",
    "        if not set(evas).issubset(data['eva'].values):\n",
    "            print(f\"Es gibt keine Bahnhöfe mit den EVA-Nummern {evas}.\")\n",
    "            return None\n",
    "        # Filtere nach den angegebenen EVA-Nummern\n",
    "        data = data[data['eva'].isin(evas)]\n",
    "    \n",
    "    # Wenn ein Datum angegeben ist, nach Jahr, Monat und Tag filtern\n",
    "    if date:\n",
    "        data['date'] = pd.to_datetime(data['planned']).dt.date\n",
    "        data = data[data['date'] == pd.to_datetime(date).date()]\n",
    "    \n",
    "    # Wenn eine Kalenderwoche angegeben ist, nach dieser filtern\n",
    "    if week_number:\n",
    "        if date:\n",
    "            print(\"Tag und Kalenderwoche können nicht gleichzeitig ausgewählt werden.\")\n",
    "            return None\n",
    "        data['week_number'] = pd.to_datetime(data['planned']).dt.isocalendar().week\n",
    "        data = data[data['week_number'] == week_number]\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel: Visualisierungsfunktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellt den Balken Graph zu den Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart_by_category_and_station_x(data, x_column='X', y_column='Y', \n",
    "                                           hue_column='station', title='', \n",
    "                                           x_axis_label='Zugkategorie', y_axis_label='Verspätungsprozentsatz', \n",
    "                                           palette='Set2', y_limit_factor=1.1, text_offset_factor=0.03, \n",
    "                                           show_values=True, fig_size_x=17, fig_size_y=8, int_value=True):\n",
    "    \"\"\"\n",
    "    Erstellt ein Balkendiagramm, das für jede Zugart (x-Achse) Balken für jeden Bahnhof oder Kalenderwoche anzeigt.\n",
    "    \n",
    "    :param data: DataFrame mit den Daten für das Diagramm.\n",
    "    :param x_column: Name der Spalte für die x-Achse (z. B. Zugkategorien).\n",
    "    :param y_column: Name der Spalte für die y-Achse (z. B. Verspätungsprozentsatz).\n",
    "    :param hue_column: Name der Spalte für die Farbcodierung (z. B. Bahnhöfe oder Kalenderwoche).\n",
    "    :param title: Titel des Diagramms.\n",
    "    :param x_axis_label: Bezeichnung der x-Achse.\n",
    "    :param y_axis_label: Bezeichnung der y-Achse.\n",
    "    :param palette: Farbpalette für die Balken (Standard: 'Set2').\n",
    "    :param y_limit_factor: Faktor für die Y-Achsen-Limit (Standard: 1.1).\n",
    "    :param text_offset_factor: Faktor zur Berechnung des Abstands für die Textanzeige (Standard: 0.03).\n",
    "    :param show_values: Boolean, ob die Werte über den Balken angezeigt werden sollen (Standard: True).\n",
    "    :param int_value: Boolean, ob die Zahlen über den Balken als int oder double angezeigt werden (Standardwert: True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Überprüfen, ob die Spalte \"week_number\" existiert, um den Namen der Legende anzupassen\n",
    "    if 'week_number' in data.columns:\n",
    "        hue_column = 'week_number'  # Ändere die Spalte für die Farbcodierung\n",
    "        legend_title = 'Kalenderwoche'  # Setze den Legendentitel\n",
    "    else:\n",
    "        legend_title = 'Bahnhof'  # Standardwert, falls es keine \"week_number\"-Spalte gibt\n",
    "    \n",
    "    # Maximalwert für die Y-Achse berechnen\n",
    "    y_limit = data[y_column].max() * y_limit_factor\n",
    "\n",
    "    # Abstand für die Zahl über den Balken berechnen\n",
    "    text_offset_max_factor = data[y_column].max() * text_offset_factor \n",
    "    \n",
    "    # Balkendiagramm erstellen\n",
    "    plt.figure(figsize=(fig_size_x, fig_size_y))\n",
    "    ax = sns.barplot(x=x_column, y=y_column, hue=hue_column, data=data, palette=palette)\n",
    "    \n",
    "    # Titel und Achsenbeschriftungen setzen\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_axis_label)\n",
    "    plt.ylabel(y_axis_label)\n",
    "    \n",
    "    # Werte über den Balken anzeigen\n",
    "    if show_values:\n",
    "        for bar in ax.patches:\n",
    "            yval = bar.get_height()\n",
    "            if yval > 0:  # Nur Werte > 0 anzeigen\n",
    "                if int_value:\n",
    "                    yval = int(yval)  # Ganze Zahl, wenn int_value True\n",
    "                else:\n",
    "                    yval = round(yval, 1)  # Eine Nachkommastelle, wenn int_value False\n",
    "\n",
    "                plt.text(\n",
    "                    bar.get_x() + bar.get_width() / 2, \n",
    "                    yval + text_offset_max_factor, \n",
    "                    f\"{yval}\",  # Anzeige des Werts\n",
    "                    ha='center', \n",
    "                    va='bottom'\n",
    "                )\n",
    "\n",
    "    # Y-Achse anpassen\n",
    "    plt.ylim(0, y_limit)\n",
    "    \n",
    "    # Legende anpassen\n",
    "    plt.legend(title=legend_title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellt einen Liniengraph zu den Zuglinien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_chart(data, title='', xlabel='', ylabel='', xsize=10, ysize=4):\n",
    "    \"\"\"\n",
    "    Erstellt einen Liniengraphen für die Daten und stellt sicher, dass die X-Achse\n",
    "    korrekt skaliert wird, abhängig davon, ob 'day_of_week' oder 'week_number' verwendet wird.\n",
    "\n",
    "    :param data: DataFrame mit Spalten 'X', 'day_of_week'/'week_number', und 'Y'.\n",
    "    :param title: Titel des Graphen.\n",
    "    :param xlabel: Beschriftung der X-Achse.\n",
    "    :param ylabel: Beschriftung der Y-Achse.\n",
    "    \"\"\"\n",
    "    if data is None or data.empty:\n",
    "        print(\"Keine Daten zum Plotten verfügbar.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(xsize, ysize))\n",
    "\n",
    "    # X-Achse bestimmen\n",
    "    if \"day_of_week\" in data.columns:\n",
    "        x_column = \"day_of_week\"\n",
    "        x_ticks = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "        # Umwandlung in numerische Werte für die Reihenfolge\n",
    "        weekdays_order = {day: i for i, day in enumerate(x_ticks)}\n",
    "        data[\"x_value\"] = data[x_column].map(weekdays_order)\n",
    "    elif \"week_number\" in data.columns:\n",
    "        x_column = \"week_number\"\n",
    "        x_ticks = sorted(data[x_column].unique())  # Alle Kalenderwochen als numerische Werte\n",
    "        data[\"x_value\"] = data[x_column]\n",
    "    else:\n",
    "        print(\"Keine gültige Spalte für die X-Achse gefunden.\")\n",
    "        return\n",
    "\n",
    "    # Linien für jede Station erstellen\n",
    "    for station, group in data.groupby(\"X\"):\n",
    "        plt.plot(group[\"x_value\"], group[\"Y\"], label=station, marker='o')\n",
    "        # Werte über den Punkten anzeigen\n",
    "        for x, y in zip(group[\"x_value\"], group[\"Y\"]):\n",
    "            plt.text(x, y, f\"{y:.2f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "    # Plot-Details\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(xlabel if xlabel else x_column, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    \n",
    "    # Anpassung der X-Ticks\n",
    "    if x_column == \"day_of_week\":\n",
    "        plt.xticks(ticks=range(len(x_ticks)), labels=x_ticks, rotation=45)\n",
    "    elif x_column == \"week_number\":\n",
    "        plt.xticks(ticks=x_ticks, labels=x_ticks)\n",
    "\n",
    "    plt.grid(visible=True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.legend(title=\"Station\", fontsize=10, title_fontsize=12)\n",
    "\n",
    "    # Plot anzeigen\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel: Datenaufbereitung entsprechend der Forschungsfragen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnet je Zugart wie viel Prozent der Züge verpätet sind. Bezieht nur Züge mit ein, deren Verstpätung höher als `delay_threshold`sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentage_delay_by_category_and_station_x(\n",
    "    data, delay_threshold=0, categories=None, combine_all_categories=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Berechnet den Prozentsatz der verspäteten Züge je Zugart und je Bahnhof sowie einen Durchschnittsbalken.\n",
    "    \n",
    "    :param data: DataFrame mit den zugrunde liegenden Daten.\n",
    "    :param delay_threshold: Schwellenwert für die Verspätung in Minuten.\n",
    "    :param categories: Optional, Liste spezifischer Zugarten zum Filtern (z. B. ['ICE', 'RE']).\n",
    "    :param combine_all_categories: Boolean, ob alle Zugarten zusammen betrachtet werden sollen. Standard: False.\n",
    "    :return: DataFrame mit den Spalten: X (Zugkategorie), Y (Verspätungsprozentsatz) und station (Bahnhof).\n",
    "    \"\"\"\n",
    "    if combine_all_categories:\n",
    "        # Alle Zugarten zusammen betrachten (trainCategory ignorieren)\n",
    "        delayed_trains = data[data['delay'] > delay_threshold]\n",
    "        total_trains = data.groupby(['station']).size()\n",
    "        delayed_trains_by_category = delayed_trains.groupby(['station']).size()\n",
    "        \n",
    "        # Prozentsatz der verspäteten Züge je Bahnhof\n",
    "        percentage_delay = (delayed_trains_by_category / total_trains) * 100\n",
    "        \n",
    "        # DataFrame mit den Ergebnissen\n",
    "        result = percentage_delay.reset_index(name='delayPercentage')\n",
    "        \n",
    "        # Spalte 'X' für Zugkategorie setzen (als \"Alle\")\n",
    "        result['X'] = 'Alle'\n",
    "    else:\n",
    "        # Optional nach spezifischen Zugarten filtern\n",
    "        if categories:\n",
    "            data = data[data['trainCategory'].isin(categories)]\n",
    "        \n",
    "        # Züge filtern, die mehr als 'delay_threshold' Minuten Verspätung haben\n",
    "        delayed_trains = data[data['delay'] > delay_threshold]\n",
    "        \n",
    "        # Zugarten getrennt betrachten (falls keine spezifische Kategorie gefiltert wurde)\n",
    "        total_trains = data.groupby(['trainCategory', 'station']).size()\n",
    "        delayed_trains_by_category = delayed_trains.groupby(['trainCategory', 'station']).size()\n",
    "        \n",
    "        # Prozentsatz der verspäteten Züge je Zugkategorie und Bahnhof\n",
    "        percentage_delay = (delayed_trains_by_category / total_trains) * 100\n",
    "        \n",
    "        # DataFrame mit den Ergebnissen\n",
    "        result = percentage_delay.reset_index(name='delayPercentage')\n",
    "        \n",
    "        # Umbenennen der Spalten für das gewünschte Format\n",
    "        result = result.rename(columns={'trainCategory': 'X'})\n",
    "    \n",
    "    # Umbenennen der Spalte für den Prozentsatz\n",
    "    result = result.rename(columns={'delayPercentage': 'Y'})\n",
    "    \n",
    "    # NaN-Werte durch 0 ersetzen und auf 2 Dezimalstellen runden\n",
    "    result['Y'] = result['Y'].fillna(0).apply(lambda x: int(x * 100) / 100)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnet die durchschnittliche Verspätung je Zugart in Minuten. Bezieht nur Züge mit ein, deren Verspätung höher als `delay_threshold` sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_min_delay_by_category_and_station_x(\n",
    "    data, delay_threshold=0, categories=None, combine_all_categories=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Berechnet die durchschnittliche Verspätung in Minuten pro Zugart und Bahnhof.\n",
    "    \n",
    "    :param data: DataFrame mit den zugrunde liegenden Daten.\n",
    "    :param delay_threshold: Minimaler Schwellenwert für die Verspätung (in Minuten), um in die Berechnung einbezogen zu werden.\n",
    "    :param categories: Optional, Liste spezifischer Zugarten zum Filtern (z. B. ['ICE', 'RE']).\n",
    "    :param combine_all_categories: Boolean, ob alle Zugarten zusammen betrachtet werden sollen. Standard: False.\n",
    "    :return: DataFrame mit den Spalten 'X' (Zugart), 'Y' (Durchschnittliche Verspätung in Minuten) und 'station' (Bahnhof).\n",
    "    \"\"\"\n",
    "    if data.empty:\n",
    "        print(\"Keine Daten für die Berechnung der Verspätung vorhanden.\")\n",
    "        return None\n",
    "\n",
    "    # Nur Züge mit einer Verspätung größer als der Schwellenwert berücksichtigen\n",
    "    delayed_data = data[data['delay'] > delay_threshold]\n",
    "    \n",
    "    if delayed_data.empty:\n",
    "        print(f\"Keine Züge mit einer Verspätung größer als {delay_threshold} Minuten gefunden.\")\n",
    "        return None\n",
    "    \n",
    "    if combine_all_categories:\n",
    "        # Alle Zugarten zusammen betrachten (trainCategory ignorieren)\n",
    "        avg_delay_by_station = delayed_data.groupby(['station'])['delay'].mean().reset_index()\n",
    "        \n",
    "        # Spalte 'X' für Zugkategorie setzen (als \"Alle\")\n",
    "        avg_delay_by_station['X'] = 'Alle'\n",
    "        \n",
    "        # Umbenennen der Spalten für das gewünschte Format\n",
    "        result = avg_delay_by_station.rename(columns={'delay': 'Y'})\n",
    "    else:\n",
    "        # Optional nach spezifischen Zugarten filtern\n",
    "        if categories:\n",
    "            delayed_data = delayed_data[delayed_data['trainCategory'].isin(categories)]\n",
    "        \n",
    "        # Durchschnittliche Verspätung pro Zugart und Bahnhof berechnen\n",
    "        avg_delay_by_category_station = delayed_data.groupby(['trainCategory', 'station'])['delay'].mean().reset_index()\n",
    "        \n",
    "        # Ergebnis formatieren\n",
    "        avg_delay_by_category_station['X'] = avg_delay_by_category_station['trainCategory']\n",
    "        avg_delay_by_category_station = avg_delay_by_category_station[['X', 'station', 'delay']]\n",
    "        \n",
    "        # Umbenennen der Spalten für das gewünschte Format\n",
    "        result = avg_delay_by_category_station.rename(columns={'delay': 'Y'})\n",
    "    \n",
    "    # Runden der durchschnittlichen Verspätung auf 1 Dezimalstelle\n",
    "    result['Y'] = result['Y'].round(1)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnet wie viel Prozent der Verspäteten Züge in eine Bestimmte Verspätungskategorie fallen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delay_statistics_by_train_type_and_station_x(data, train_type=None):\n",
    "    \"\"\"\n",
    "    Berechnet die Statistik der Verspätungen für bestimmte Zugarten oder für alle Züge,\n",
    "    wenn keine Zugart angegeben ist, aus einem bereits gefilterten DataFrame.\n",
    "    \n",
    "    :param data: DataFrame, das die bereits gefilterten Daten enthält.\n",
    "    :param train_type: Liste von Zugarten, für die die Statistik berechnet werden soll. \n",
    "                       Wenn None, wird für alle Zugarten berechnet.\n",
    "    :return: DataFrame mit den Verspätungskategorien (X) und deren prozentualem Anteil (Y) sowie der Stationen-Spalte.\n",
    "    \"\"\"\n",
    "    # Wenn Zugarten angegeben sind, nur diese berücksichtigen\n",
    "    if train_type:\n",
    "        data = data[data['trainCategory'].isin(train_type)]\n",
    "    \n",
    "    # Überprüfen, ob es nach der Filterung noch Daten gibt\n",
    "    if data.empty:\n",
    "        print(f\"Keine Daten für die Zugart '{train_type}' gefunden.\" if train_type else \"Keine Daten gefunden.\")\n",
    "        return None\n",
    "    \n",
    "    # Filtere auf Züge mit einer positiven Verspätung\n",
    "    df_delayed = data[data['delay'] > 0]\n",
    "    \n",
    "    # Überprüfen, ob es verspätete Züge gibt\n",
    "    if df_delayed.empty:\n",
    "        print(f\"Es gibt keine verspäteten Züge.\")\n",
    "        return None\n",
    "\n",
    "    # Gesamtanzahl der verspäteten Züge\n",
    "    total_delays = len(df_delayed)\n",
    "    \n",
    "    # Berechnung des prozentualen Anteils in jeder Kategorie und nach Station\n",
    "    delay_stats = []\n",
    "    for station in df_delayed['station'].unique():  # Gruppiert nach Station\n",
    "        station_data = df_delayed[df_delayed['station'] == station]\n",
    "        \n",
    "        stats = {\n",
    "            'station': station,\n",
    "            '< 10 min': (station_data['delay'] < 10).sum() / len(station_data) * 100,\n",
    "            '< 30 min': ((station_data['delay'] >= 10) & (station_data['delay'] < 30)).sum() / len(station_data) * 100,\n",
    "            '< 60 min': ((station_data['delay'] >= 30) & (station_data['delay'] < 60)).sum() / len(station_data) * 100,\n",
    "            '< 120 min': ((station_data['delay'] >= 60) & (station_data['delay'] < 120)).sum() / len(station_data) * 100,\n",
    "            '> 120 min': (station_data['delay'] >= 120).sum() / len(station_data) * 100\n",
    "        }\n",
    "        delay_stats.append(stats)\n",
    "\n",
    "    # Umwandlung der Statistik in einen DataFrame\n",
    "    stats_df = pd.DataFrame(delay_stats)\n",
    "    \n",
    "    # Reshape für die Darstellung der Kategorien in der Spalte 'X'\n",
    "    stats_df = pd.melt(stats_df, id_vars=['station'], var_name='X', value_name='Y')\n",
    "\n",
    "    # Optional: Y-Werte runden\n",
    "    stats_df['Y'] = stats_df['Y'].apply(lambda x: round(x, 1))\n",
    "\n",
    "    return stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delay_by_line_and_day(data, line='', output_type=\"%\", delay_threshold=0):\n",
    "    \"\"\"\n",
    "    Berechnet den Prozentsatz oder die durchschnittliche Verspätung einer bestimmten Zuglinie je Wochentag und Bahnhof.\n",
    "    \"\"\"\n",
    "    if data.empty:\n",
    "        print(\"Keine Daten verfügbar.\")\n",
    "        return None\n",
    "\n",
    "    # Nach der gewünschten Linie filtern\n",
    "    filtered_data = data[data[\"Verbindung\"] == line].copy()\n",
    "    if filtered_data.empty:\n",
    "        print(f\"Keine Daten für die Linie {line} gefunden.\")\n",
    "        return None\n",
    "\n",
    "    # Verspätung filtern\n",
    "    delayed_data = filtered_data[filtered_data[\"delay\"] > delay_threshold].copy()\n",
    "\n",
    "    # Wochentag hinzufügen (mit .loc, um die Warnung zu vermeiden)\n",
    "    filtered_data.loc[:, \"day_of_week\"] = pd.to_datetime(filtered_data[\"planned\"]).dt.day_name()\n",
    "    delayed_data.loc[:, \"day_of_week\"] = pd.to_datetime(delayed_data[\"planned\"]).dt.day_name()\n",
    "\n",
    "    # Gruppierung nach Bahnhof und Wochentag\n",
    "    if output_type == \"%\":\n",
    "        total_trains = filtered_data.groupby([\"station\", \"day_of_week\"]).size()\n",
    "        delayed_trains = delayed_data.groupby([\"station\", \"day_of_week\"]).size()\n",
    "        result = (delayed_trains / total_trains) * 100\n",
    "    elif output_type == \"min\":\n",
    "        result = delayed_data.groupby([\"station\", \"day_of_week\"])[\"delay\"].mean()\n",
    "    else:\n",
    "        print(\"Ungültiger output_type. Bitte 'min' oder '%' angeben.\")\n",
    "        return None\n",
    "\n",
    "    # Ergebnis in DataFrame umwandeln\n",
    "    result = result.reset_index(name=\"Y\")\n",
    "    result = result.rename(columns={\"station\": \"X\"})  # Format für die Spalte X und Y\n",
    "    \n",
    "    # Runden der Ergebnisse\n",
    "    if output_type == \"%\":\n",
    "        result[\"Y\"] = result[\"Y\"].fillna(0).round(2)\n",
    "    elif output_type == \"min\":\n",
    "        result[\"Y\"] = result[\"Y\"].round(1)\n",
    "\n",
    "    # Benutzerdefinierte Sortierung der Wochentage\n",
    "    weekdays_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    result[\"day_of_week\"] = pd.Categorical(result[\"day_of_week\"], categories=weekdays_order, ordered=True)\n",
    "    result = result.sort_values(by=[\"X\", \"day_of_week\"]).reset_index(drop=True)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cancellations_by_train_type_and_station(\n",
    "    data, \n",
    "    train_types=None,  # Neuer Parameter für die Liste der Zugarten\n",
    "    calculate_percentage=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Berechnet entweder den Prozentsatz oder die absolute Anzahl ausgefallener Züge \n",
    "    je Zugart und Bahnhof. Optional kann eine Liste von Zugarten übergeben werden, \n",
    "    um nur die Daten für diese Zugarten zu berechnen. Wenn keine Liste übergeben wird, \n",
    "    werden alle Zugarten berücksichtigt.\n",
    "    \n",
    "    :param data: DataFrame mit den zugrunde liegenden Daten.\n",
    "    :param train_types: Liste der Zugarten, für die die Berechnungen durchgeführt werden sollen (Optional).\n",
    "    :param calculate_percentage: Boolean, ob der Prozentsatz (True) oder die absolute Anzahl (False) berechnet werden soll.\n",
    "    :return: DataFrame mit den Spalten: X (Zugart), Y (Wert je nach Auswahl) und station (Bahnhof).\n",
    "    \"\"\"\n",
    "    # Filtern der ausgefallenen Züge\n",
    "    cancelled_trains = data[data['eventStatus'] == 'c']\n",
    "    \n",
    "    # Wenn eine Liste von Zugarten übergeben wurde, filtern wir die Daten\n",
    "    if train_types:\n",
    "        cancelled_trains = cancelled_trains[cancelled_trains['trainCategory'].isin(train_types)]\n",
    "        data = data[data['trainCategory'].isin(train_types)]\n",
    "    \n",
    "    # Berechnung der Züge pro Zugart und Bahnhof, auch für Zugarten ohne Verspätung\n",
    "    total_trains = data.groupby(['trainCategory', 'station']).size()\n",
    "    \n",
    "    # Wenn keine ausgefallenen Züge vorhanden sind, setzen wir sie auf 0\n",
    "    cancellations = cancelled_trains.groupby(['trainCategory', 'station']).size().reindex(total_trains.index, fill_value=0)\n",
    "    \n",
    "    if calculate_percentage:\n",
    "        # Berechnung des Prozentsatzes\n",
    "        percentage_cancellations = (cancellations / total_trains) * 100\n",
    "        \n",
    "        # Umwandlung in DataFrame\n",
    "        result = percentage_cancellations.reset_index(name='Y')\n",
    "    else:\n",
    "        # Umwandlung in DataFrame\n",
    "        result = cancellations.reset_index(name='Y')\n",
    "    \n",
    "    # Hinzufügen der X-Achsen-Spalte (Zugart)\n",
    "    result = result.rename(columns={'trainCategory': 'X'})\n",
    "    \n",
    "    # NaN-Werte durch 0 ersetzen und Zahlen auf zwei Dezimalstellen runden\n",
    "    result['Y'] = result['Y'].fillna(0).apply(lambda x: int(x * 100) / 100 if calculate_percentage else int(x))\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cancellations_by_operator_and_station(\n",
    "    data, \n",
    "    operators=None,  # Neuer Parameter: Liste von Operatoren\n",
    "    calculate_percentage=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Berechnet entweder den Prozentsatz oder die absolute Anzahl ausgefallener Züge \n",
    "    je Operator und Bahnhof. Optional kann eine Liste von Operatoren übergeben werden, \n",
    "    um nur die Daten für diese Operatoren zu berechnen. Wenn keine Liste übergeben wird, \n",
    "    werden alle Operatoren berücksichtigt.\n",
    "    \n",
    "    :param data: DataFrame mit den zugrunde liegenden Daten.\n",
    "    :param operators: Liste von Operatoren, für die die Berechnungen durchgeführt werden sollen (Optional).\n",
    "    :param calculate_percentage: Boolean, ob der Prozentsatz (True) oder die absolute Anzahl (False) berechnet werden soll.\n",
    "    :return: DataFrame mit den Spalten: X (Operator), Y (Wert je nach Auswahl) und station (Bahnhof).\n",
    "    \"\"\"\n",
    "    # Filtern der ausgefallenen Züge\n",
    "    cancelled_trains = data[data['eventStatus'] == 'c']\n",
    "    \n",
    "    # Wenn eine Liste von Operatoren übergeben wurde, filtern wir die Daten\n",
    "    if operators:\n",
    "        cancelled_trains = cancelled_trains[cancelled_trains['operator'].isin(operators)]\n",
    "        data = data[data['operator'].isin(operators)]\n",
    "    \n",
    "    # Berechnung der Züge pro Operator und Bahnhof, auch für Operatoren ohne Verspätung\n",
    "    total_trains = data.groupby(['operator', 'station']).size()\n",
    "    \n",
    "    # Wenn keine ausgefallenen Züge vorhanden sind, setzen wir sie auf 0\n",
    "    cancellations = cancelled_trains.groupby(['operator', 'station']).size().reindex(total_trains.index, fill_value=0)\n",
    "    \n",
    "    if calculate_percentage:\n",
    "        # Berechnung des Prozentsatzes\n",
    "        percentage_cancellations = (cancellations / total_trains) * 100\n",
    "        \n",
    "        # Umwandlung in DataFrame\n",
    "        result = percentage_cancellations.reset_index(name='Y')\n",
    "    else:\n",
    "        # Umwandlung in DataFrame\n",
    "        result = cancellations.reset_index(name='Y')\n",
    "    \n",
    "    # Hinzufügen der X-Achsen-Spalte (Operator)\n",
    "    result = result.rename(columns={'operator': 'X'})\n",
    "    \n",
    "    # NaN-Werte durch 0 ersetzen und Zahlen auf zwei Dezimalstellen runden\n",
    "    result['Y'] = result['Y'].fillna(0).apply(lambda x: int(x * 100) / 100 if calculate_percentage else int(x))\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cancellations_by_line_and_day(data, line='', output_type='absolute', group_by='day_of_week'):\n",
    "    \"\"\"\n",
    "    Berechnet entweder die Ausfallquote oder die absoluten Ausfälle je Gruppierungskriterium (Wochentag/Kalenderwoche)\n",
    "    und Bahnhof für eine bestimmte Linie.\n",
    "\n",
    "    Parameters:\n",
    "    - data: Der DataFrame mit den Zugdaten.\n",
    "    - line: Die Linie, für die die Ausfälle berechnet werden sollen.\n",
    "    - output_type: Gibt an, ob die Ausgabe die Ausfallquote (%) oder die absolute Zahl der Ausfälle ('absolute') ist.\n",
    "    - group_by: Gibt an, ob die Gruppierung nach Wochentagen ('day_of_week') oder Kalenderwochen ('week_number') erfolgen soll.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame mit Spalten 'X' (Station), Gruppierungskriterium ('day_of_week'/'week_number'), und 'Y' (Ausfallwerte).\n",
    "    \"\"\"\n",
    "    if data.empty:\n",
    "        print(\"Keine Daten verfügbar.\")\n",
    "        return None\n",
    "\n",
    "    # Nach der gewünschten Linie filtern\n",
    "    filtered_data = data[data[\"Verbindung\"] == line].copy()\n",
    "    if filtered_data.empty:\n",
    "        print(f\"Keine Daten für die Linie {line} gefunden.\")\n",
    "        return None\n",
    "\n",
    "    # Füge die Spalte für Wochentage oder Kalenderwochen hinzu\n",
    "    if group_by == 'day_of_week':\n",
    "        filtered_data[\"day_of_week\"] = pd.to_datetime(filtered_data[\"planned\"]).dt.day_name()\n",
    "        day_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "        filtered_data[\"day_of_week\"] = pd.Categorical(filtered_data[\"day_of_week\"], categories=day_order, ordered=True)\n",
    "    elif group_by == 'week_number':\n",
    "        filtered_data[\"week_number\"] = pd.to_datetime(filtered_data[\"planned\"]).dt.isocalendar().week\n",
    "    else:\n",
    "        print(\"Ungültiger group_by-Wert. Bitte 'day_of_week' oder 'week_number' angeben.\")\n",
    "        return None\n",
    "\n",
    "    # Nur ausgefallene Züge berücksichtigen (eventStatus == 'c')\n",
    "    cancelled_data = filtered_data[filtered_data[\"eventStatus\"] == 'c'].copy()\n",
    "\n",
    "    # Alle Stationen und Gruppierungswerte sicherstellen\n",
    "    all_stations = filtered_data[\"station\"].unique()\n",
    "    all_group_values = filtered_data[group_by].dropna().unique()\n",
    "\n",
    "    # Ergebnis für alle Kombinationen von Station und Gruppierungswert initialisieren\n",
    "    result = pd.MultiIndex.from_product([all_stations, all_group_values], names=[\"station\", group_by])\n",
    "    result = pd.DataFrame(index=result).reset_index()\n",
    "\n",
    "    # Gruppierung nach Bahnhof und Gruppierungskriterium\n",
    "    if output_type == 'absolute':\n",
    "        cancelled_trains = cancelled_data.groupby([\"station\", group_by]).size().reset_index(name=\"cancelled_trains\")\n",
    "\n",
    "        # Merge der Gruppen mit den Gruppierungswerten und Stationen\n",
    "        result = result.merge(cancelled_trains, how=\"left\", on=[\"station\", group_by])\n",
    "\n",
    "        # Absolute Ausfälle (ersetzen von NaN mit 0)\n",
    "        result[\"Y\"] = result[\"cancelled_trains\"].fillna(0).astype(int)\n",
    "        result.drop(columns=[\"cancelled_trains\"], inplace=True)\n",
    "\n",
    "    elif output_type == '%':\n",
    "        cancelled_trains = cancelled_data.groupby([\"station\", group_by]).size().reset_index(name=\"cancelled_trains\")\n",
    "\n",
    "        # Berechnung der Ausfallquote in Prozent\n",
    "        result = result.merge(cancelled_trains, how=\"left\", on=[\"station\", group_by])\n",
    "\n",
    "        # Ausfallquote in Prozent berechnen\n",
    "        total_trains = len(filtered_data)\n",
    "        if total_trains > 0:\n",
    "            result[\"Y\"] = (result[\"cancelled_trains\"] / total_trains) * 100\n",
    "        else:\n",
    "            result[\"Y\"] = 0\n",
    "        result[\"Y\"] = result[\"Y\"].fillna(0).round(2)\n",
    "        result.drop(columns=[\"cancelled_trains\"], inplace=True)\n",
    "\n",
    "    else:\n",
    "        print(\"Ungültiger output_type. Bitte 'absolute' oder '%' angeben.\")\n",
    "        return None\n",
    "\n",
    "    # Sortieren der Ergebnisse basierend auf dem Gruppierungswert\n",
    "    result = result.sort_values(by=[\"station\", group_by]).reset_index(drop=True)\n",
    "\n",
    "    # Umbenennen der 'station' Spalte in 'X'\n",
    "    result.rename(columns={\"station\": \"X\"}, inplace=True)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cancellations_by_operator_and_week(\n",
    "    data, \n",
    "    operator=None,  # Neuer Parameter für den Operator\n",
    "    calculate_percentage=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Berechnet entweder den Prozentsatz oder die absolute Anzahl ausgefallener Züge \n",
    "    je Operator und Kalenderwoche. Optional kann ein bestimmter Operator übergeben werden, \n",
    "    um nur die Daten für diesen Operator zu berechnen. Wenn kein Operator übergeben wird, \n",
    "    werden auch Operatoren ohne Verspätungen berücksichtigt.\n",
    "    \n",
    "    :param data: DataFrame mit den zugrunde liegenden Daten.\n",
    "    :param operator: Der Operator, für den die Berechnungen durchgeführt werden sollen (Optional).\n",
    "    :param calculate_percentage: Boolean, ob der Prozentsatz (True) oder die absolute Anzahl (False) berechnet werden soll.\n",
    "    :return: DataFrame mit den Spalten: X (Operator), Y (Wert je nach Auswahl) und week_number (Kalenderwoche).\n",
    "    \"\"\"\n",
    "    # Filtern der ausgefallenen Züge\n",
    "    cancelled_trains = data[data['eventStatus'] == 'c']\n",
    "    \n",
    "    # Wenn ein bestimmter Operator übergeben wird, filtern wir die Daten\n",
    "    if operator:\n",
    "        cancelled_trains = cancelled_trains[cancelled_trains['operator'] == operator]\n",
    "        data = data[data['operator'] == operator]\n",
    "    \n",
    "    # Berechnung der Züge pro Operator und Kalenderwoche, auch für Operatoren ohne Verspätung\n",
    "    total_trains = data.groupby(['operator', 'week_number']).size()\n",
    "    \n",
    "    # Wenn keine ausgefallenen Züge vorhanden sind, setzen wir sie auf 0\n",
    "    cancellations = cancelled_trains.groupby(['operator', 'week_number']).size().reindex(total_trains.index, fill_value=0)\n",
    "    \n",
    "    if calculate_percentage:\n",
    "        # Berechnung des Prozentsatzes\n",
    "        percentage_cancellations = (cancellations / total_trains) * 100\n",
    "        \n",
    "        # Umwandlung in DataFrame\n",
    "        result = percentage_cancellations.reset_index(name='Y')\n",
    "    else:\n",
    "        # Umwandlung in DataFrame\n",
    "        result = cancellations.reset_index(name='Y')\n",
    "    \n",
    "    # Hinzufügen der X-Achsen-Spalte (Operator)\n",
    "    result = result.rename(columns={'operator': 'X'})\n",
    "    \n",
    "    # NaN-Werte durch 0 ersetzen und Zahlen auf zwei Dezimalstellen runden\n",
    "    result['Y'] = result['Y'].fillna(0).apply(lambda x: int(x * 100) / 100 if calculate_percentage else int(x))\n",
    "\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cancellations_by_week(\n",
    "    data, \n",
    "    calculate_percentage=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Berechnet entweder den Prozentsatz oder die absolute Anzahl ausgefallener Züge je Kalenderwoche, \n",
    "    unabhängig von den Betreibern.\n",
    "    \n",
    "    :param data: DataFrame mit den zugrunde liegenden Daten.\n",
    "    :param calculate_percentage: Boolean, ob der Prozentsatz (True) oder die absolute Anzahl (False) berechnet werden soll.\n",
    "    :return: DataFrame mit den Spalten: 'X' (Kalenderwoche), 'Y' (Wert je nach Auswahl).\n",
    "    \"\"\"\n",
    "    # Filtern der ausgefallenen Züge\n",
    "    cancelled_trains = data[data['eventStatus'] == 'c']\n",
    "    \n",
    "    # Berechnung der Züge pro Woche\n",
    "    total_trains_per_week = data.groupby(['week_number']).size()\n",
    "    \n",
    "    # Berechnung der Ausfälle pro Woche\n",
    "    cancellations_per_week = cancelled_trains.groupby(['week_number']).size().reindex(total_trains_per_week.index, fill_value=0)\n",
    "    \n",
    "    if calculate_percentage:\n",
    "        # Berechnung des Prozentsatzes\n",
    "        percentage_cancellations = (cancellations_per_week / total_trains_per_week) * 100\n",
    "        \n",
    "        # Umwandlung in DataFrame\n",
    "        result = percentage_cancellations.reset_index(name='Y')\n",
    "    else:\n",
    "        # Umwandlung in DataFrame\n",
    "        result = cancellations_per_week.reset_index(name='Y')\n",
    "    \n",
    "    # Hinzufügen der X-Achsen-Spalte (Kalenderwoche)\n",
    "    result = result.rename(columns={'week_number': 'X'})\n",
    "    \n",
    "    # NaN-Werte durch 0 ersetzen und Zahlen auf zwei Dezimalstellen runden\n",
    "    result['Y'] = result['Y'].fillna(0).apply(lambda x: int(x * 100) / 100 if calculate_percentage else int(x))\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cancellation_statistics_by_train_type_and_station(data, train_types=None):\n",
    "    \"\"\"\n",
    "    Berechnet die Statistik der Zugausfälle nach Zugart und Station basierend auf der cancellation_delay.\n",
    "    \n",
    "    :param data: DataFrame mit den Spalten 'eventStatus', 'cancellation_delay', 'station', und 'trainCategory'.\n",
    "    :param train_type: Liste von Zugarten, für die die Statistik berechnet werden soll. \n",
    "                       Wenn None, wird für alle Zugarten berechnet.\n",
    "    :return: DataFrame mit den Kategorien (X), den Stationen und dem prozentualen Anteil (Y).\n",
    "    \"\"\"\n",
    "    # Filter für ausgefallene Züge\n",
    "    cancelled_trains = data[data['eventStatus'] == 'c']\n",
    "    \n",
    "    # Filtern nach Zugarten, falls train_type angegeben ist\n",
    "    if train_types:\n",
    "        cancelled_trains = cancelled_trains[cancelled_trains['trainCategory'].isin(train_types)]\n",
    "    \n",
    "    # Überprüfen, ob es nach der Filterung noch Daten gibt\n",
    "    if cancelled_trains.empty:\n",
    "        print(f\"Keine ausgefallenen Züge für die Zugart '{train_types}' gefunden.\" if train_types else \"Keine ausgefallenen Züge gefunden.\")\n",
    "        return None\n",
    "\n",
    "    # Kategorien für cancellation_delay definieren\n",
    "    categories = {\n",
    "        '> 120 min vorher': cancelled_trains['cancellation_delay'] <= -120,\n",
    "        '> 60 min vorher': (cancelled_trains['cancellation_delay'] > -120) & (cancelled_trains['cancellation_delay'] <= -60),\n",
    "        '> 30 min vorher': (cancelled_trains['cancellation_delay'] > -60) & (cancelled_trains['cancellation_delay'] <= -30),\n",
    "        '> 0 min vorher': (cancelled_trains['cancellation_delay'] > -30) & (cancelled_trains['cancellation_delay'] <= 0),\n",
    "        '< 30 min nachher': (cancelled_trains['cancellation_delay'] > 0) & (cancelled_trains['cancellation_delay'] <= 30),\n",
    "        '< 60 min nachher': (cancelled_trains['cancellation_delay'] > 30) & (cancelled_trains['cancellation_delay'] <= 60),\n",
    "        '> 60 min nachher': cancelled_trains['cancellation_delay'] > 60,\n",
    "    }\n",
    "\n",
    "    # Berechnung des Anteils der Kategorien pro Station\n",
    "    cancellation_stats = []\n",
    "    for station in cancelled_trains['station'].unique():\n",
    "        station_data = cancelled_trains[cancelled_trains['station'] == station]\n",
    "        \n",
    "        stats = {'station': station}\n",
    "        total_cancellations = len(station_data)\n",
    "        \n",
    "        for category, condition in categories.items():\n",
    "            stats[category] = condition[station_data.index].sum() / total_cancellations * 100\n",
    "        \n",
    "        cancellation_stats.append(stats)\n",
    "    \n",
    "    # Umwandlung der Statistik in einen DataFrame\n",
    "    stats_df = pd.DataFrame(cancellation_stats)\n",
    "    \n",
    "    # Reshape für die Darstellung der Kategorien in der Spalte 'X'\n",
    "    stats_df = pd.melt(stats_df, id_vars=['station'], var_name='X', value_name='Y')\n",
    "    \n",
    "    # Optional: Y-Werte runden\n",
    "    stats_df['Y'] = stats_df['Y'].apply(lambda x: round(x, 1))\n",
    "    \n",
    "    return stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cancellations_by_week(data, x_column='X', y_column='Y', title='Ausfälle pro Kalenderwoche', \n",
    "                               x_axis_label='Kalenderwoche', y_axis_label='Verspätungsprozentsatz', \n",
    "                               palette='Set2', fig_size_x=10, fig_size_y=6):\n",
    "    \"\"\"\n",
    "    Erstellt ein Balkendiagramm, das die Ausfälle pro Kalenderwoche zeigt.\n",
    "    \n",
    "    :param data: DataFrame mit den Daten für das Diagramm (Spalten: 'X' und 'Y').\n",
    "    :param x_column: Name der Spalte für die x-Achse (z. B. Kalenderwoche).\n",
    "    :param y_column: Name der Spalte für die y-Achse (z. B. Verspätungsprozentsatz).\n",
    "    :param title: Titel des Diagramms.\n",
    "    :param x_axis_label: Bezeichnung der x-Achse.\n",
    "    :param y_axis_label: Bezeichnung der y-Achse.\n",
    "    :param palette: Farbpalette für die Balken (Standard: 'Set2').\n",
    "    :param fig_size_x: Breite der Figur.\n",
    "    :param fig_size_y: Höhe der Figur.\n",
    "    \"\"\"\n",
    "    # Balkendiagramm erstellen\n",
    "    plt.figure(figsize=(fig_size_x, fig_size_y))\n",
    "    ax = sns.barplot(x=x_column, y=y_column, data=data, palette=palette)\n",
    "    \n",
    "    # Titel und Achsenbeschriftungen setzen\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_axis_label)\n",
    "    plt.ylabel(y_axis_label)\n",
    "    \n",
    "    # Werte über den Balken anzeigen\n",
    "    for bar in ax.patches:\n",
    "        yval = bar.get_height()\n",
    "        if yval > 0:  # Nur Werte > 0 anzeigen\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width() / 2, \n",
    "                yval + 0.1, \n",
    "                f\"{yval:.2f}\",  # Anzeige des Werts\n",
    "                ha='center', \n",
    "                va='bottom'\n",
    "            )\n",
    "    \n",
    "    # Layout anpassen und Diagramm anzeigen\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel: Reorder-Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_calculate_percentage_delay_by_category_and_station_x(df, füller='-'):\n",
    "    \"\"\"\n",
    "    Diese Funktion nimmt ein DataFrame mit den Spalten 'Zugart', 'Station' und 'Y' und strukturiert es in eine Pivot-Tabelle um.\n",
    "    Jede Zugart wird zur Zeile, jede Station zur Spalte, und der Wert 'Y' wird als Inhalt verwendet.\n",
    "    Leere Zellen werden mit dem angegebenen Füllwert gefüllt.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): Das Eingabedaten-Frame mit den Spalten 'Zugart', 'Station' und 'Y'.\n",
    "    füller: Der Wert, mit dem leere Zellen gefüllt werden sollen (Standard: '-').\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Das umstrukturierte DataFrame.\n",
    "    \"\"\"\n",
    "    df = df.rename(columns={'X': 'Zugart'})\n",
    "    df = df.rename(columns={'station': 'Banhöfe'})\n",
    "    # Pivot-Tabelle erstellen, mit 'Zugart' als Index, 'Station' als Spalten und 'Y' als Werte\n",
    "    pivot_df = df.pivot_table(index='Zugart', columns='Banhöfe', values='Y', aggfunc='first')\n",
    "    \n",
    "    # Leere Zellen mit dem Füllwert ersetzen\n",
    "    pivot_df = pivot_df.fillna(füller)\n",
    "    \n",
    "    return pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def reorder_calculate_delay_statistics_by_train_type_and_station_x(df, fueller=\"-\"):\n",
    "    \"\"\"\n",
    "    Diese Funktion nimmt ein DataFrame und wandelt es in eine Tabelle um, bei der 'X' (Zugart) als Zeilenüberschrift dient.\n",
    "    Die Werte von 'station' werden zu den Spaltenüberschriften und die entsprechenden 'Y'-Werte werden in den Zellen abgebildet.\n",
    "    Leere Zellen werden mit dem angegebenen Füllwert gefüllt (Standard ist \"-\").\n",
    "    Die Reihenfolge der 'X'-Spalte wird explizit auf '< 10 min', '< 30 min', '< 60 min', '< 120 min', '> 120 min' festgelegt.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): Das DataFrame mit den zu transformierenden Daten.\n",
    "    fueller (str): Der Wert, der für leere Zellen verwendet wird (optional, Standard ist \"-\").\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Das umstrukturierte DataFrame.\n",
    "    \"\"\"\n",
    "    df = df.rename(columns={'X': 'Kategorie'})\n",
    "    df = df.rename(columns={'station': 'Banhöfe'})\n",
    "\n",
    "    # Definiere eine benutzerdefinierte Reihenfolge für die 'X'-Spalte\n",
    "    categorie_order = ['< 10 min', '< 30 min', '< 60 min', '< 120 min', '> 120 min']\n",
    "\n",
    "    # 'X'-Spalte in eine kategorielle Variable mit definierter Reihenfolge umwandeln\n",
    "    df['Kategorie'] = pd.Categorical(df['Kategorie'], categories=categorie_order, ordered=True)\n",
    "\n",
    "    # Pivot-Tabelle erstellen, wobei 'X' (Zugart) zu den Zeilen und 'station' zu den Spalten wird\n",
    "    df_pivot = df.pivot_table(index='Kategorie', columns='Banhöfe', values='Y', aggfunc='first')\n",
    "\n",
    "    # Alle leeren Zellen mit dem Füllwert ersetzen\n",
    "    df_pivot = df_pivot.fillna(fueller)\n",
    "\n",
    "    # Die Zeilen und Spalten sortieren\n",
    "    df_pivot = df_pivot.sort_index(axis=1).sort_index(axis=0)\n",
    "\n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_calculate_cancellations_by_operator_and_station(df, füller='-'):\n",
    "    \"\"\"\n",
    "    Diese Funktion nimmt ein DataFrame mit den Spalten 'Zugart', 'Station' und 'Y' und strukturiert es in eine Pivot-Tabelle um.\n",
    "    Jede Zugart wird zur Zeile, jede Station zur Spalte, und der Wert 'Y' wird als Inhalt verwendet.\n",
    "    Leere Zellen werden mit dem angegebenen Füllwert gefüllt.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): Das Eingabedaten-Frame mit den Spalten 'Zugart', 'Station' und 'Y'.\n",
    "    füller: Der Wert, mit dem leere Zellen gefüllt werden sollen (Standard: '-').\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Das umstrukturierte DataFrame.\n",
    "    \"\"\"\n",
    "    df = df.rename(columns={'X': 'Betreiber'})\n",
    "    df = df.rename(columns={'station': 'Banhöfe'})\n",
    "    # Pivot-Tabelle erstellen, mit 'Zugart' als Index, 'Station' als Spalten und 'Y' als Werte\n",
    "    pivot_df = df.pivot_table(index='Betreiber', columns='Banhöfe', values='Y', aggfunc='first')\n",
    "    \n",
    "    # Leere Zellen mit dem Füllwert ersetzen\n",
    "    pivot_df = pivot_df.fillna(füller)\n",
    "    \n",
    "    return pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_calculate_delay_by_line_and_day(df, filler='-'):\n",
    "    \"\"\"\n",
    "    Diese Funktion nimmt ein DataFrame mit Bahnhöfen, Wochentagen und Werten,\n",
    "    und strukturiert es so um, dass die Bahnhöfe als Spaltenüberschriften\n",
    "    und die Wochentage als Zeilenüberschriften erscheinen.\n",
    "    \n",
    "    Args:\n",
    "    df (DataFrame): Das Eingabedatenframe mit den Spalten 'X', 'day_of_week' und 'Y'.\n",
    "    filler: Der Wert, der in leere Zellen (NaN-Werte) eingefügt werden soll. Standardwert ist '-'.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Ein umstrukturiertes DataFrame mit Füllwerten.\n",
    "    \"\"\"\n",
    "    # Pivot das DataFrame, so dass die Wochentage in den Zeilen und die Bahnhöfe in den Spalten erscheinen\n",
    "    df_umstrukturiert = df.pivot(index='day_of_week', columns='X', values='Y')\n",
    "    \n",
    "    # Optional: Die Spaltenüberschriften umbenennen, falls erforderlich\n",
    "    df_umstrukturiert.columns.name = None  # Entfernt den Namen der Spalte (Bahnhöfe)\n",
    "    \n",
    "    # Leere Zellen (NaN) mit dem Füllwert ersetzen\n",
    "    df_umstrukturiert = df_umstrukturiert.fillna(filler)\n",
    "    \n",
    "    # Das Ergebnis zurückgeben\n",
    "    return df_umstrukturiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_calculate_cancellation_statistics_by_train_type_and_station(df):\n",
    "    # Definieren der gewünschten Reihenfolge der Kategorien\n",
    "    categories_order = ['> 120 min vorher', '> 60 min vorher', '> 30 min vorher', '> 0 min vorher',\n",
    "                        '< 30 min nachher', '< 60 min nachher', '> 60 min nachher']\n",
    "    \n",
    "    # Umwandeln der 'X'-Spalte in einen Categorical-Typ mit der definierten Reihenfolge\n",
    "    df['X'] = pd.Categorical(df['X'], categories=categories_order, ordered=True)\n",
    "    \n",
    "    # Pivotieren der Tabelle, um die Stationen als Spalten und Kategorien als Zeilen zu erhalten\n",
    "    df_pivot = df.pivot_table(index='X', columns='station', values='Y', aggfunc='first')\n",
    "\n",
    "    # Ersetzen von NaN-Werten mit \"-\"\n",
    "    df_pivot = df_pivot.fillna(\"-\")\n",
    "\n",
    "    # Zurücksetzen des Index\n",
    "    df_pivot.reset_index(inplace=True)\n",
    "\n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel: CSV Erstellung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(df, dateiname):\n",
    "    \"\"\"\n",
    "    Diese Funktion nimmt ein DataFrame und speichert es als CSV-Datei mit Semikolon als Separator\n",
    "    und Komma als Dezimaltrennzeichen.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): Das DataFrame mit den zu exportierenden Daten.\n",
    "    dateiname (str): Der Name der CSV-Datei, die erstellt werden soll (inkl. Pfad).\n",
    "    \"\"\"\n",
    "    # Zahlen mit Komma als Dezimaltrennzeichen und Semikolon als Separator speichern\n",
    "    df.to_csv(dateiname, sep=\";\", index=True, decimal=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ersetze_char_in_csv(dateipfad, alter_char, neuer_char):\n",
    "    \"\"\"\n",
    "    Diese Funktion ersetzt einen bestimmten Charakter in einer CSV-Datei durch einen anderen.\n",
    "    \n",
    "    Args:\n",
    "    dateipfad (str): Der Pfad zur CSV-Datei.\n",
    "    alter_char (str): Der zu ersetzende Charakter.\n",
    "    neuer_char (str): Der Charakter, durch den der alte ersetzt werden soll.\n",
    "    \"\"\"\n",
    "    # CSV-Datei einlesen\n",
    "    df = pd.read_csv(dateipfad, sep=';', engine='python')\n",
    "    \n",
    "    # Durch alle Zellen im DataFrame iterieren und den Charakter ersetzen\n",
    "    df = df.applymap(lambda x: str(x).replace(alter_char, neuer_char) if isinstance(x, str) else x)\n",
    "    \n",
    "    # CSV-Datei mit den ersetzten Werten speichern\n",
    "    df.to_csv(dateipfad, sep=';', index=False, decimal=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel: Datenauswahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CSV-Daten laden\n",
    "arrival_data = load_csv_as_data_x('db-data/ar_superquery.csv')\n",
    "depature_data = load_csv_as_data_x('db-data/dp_superquery.csv')\n",
    "\n",
    "\n",
    "# 2. Daten filtern (optional)\n",
    "arrival_filtered_data = filter_data_x(\n",
    "    data=arrival_data,\n",
    "    evas=None,          # Bahnhof nach EVA-Nummer (Optional, None wenn nicht benötigt, z.B. 8000244, 8000250 oder 8000134)\n",
    "    date=None,         # Datum im Format 'YYYY-MM-DD' (Optional, None wenn nicht benötigt)\n",
    "    week_number=None   # Kalenderwoche (Optional, None wenn nicht benötigt)\n",
    ")\n",
    "\n",
    "depature_filtered_data = filter_data_x(\n",
    "    data=depature_data,\n",
    "    evas=None,          # Bahnhof nach EVA-Nummer (Optional, None wenn nicht benötigt, z.B. 8000244, 8000250 oder 8000134)\n",
    "    date=None,         # Datum im Format 'YYYY-MM-DD' (Optional, None wenn nicht benötigt)\n",
    "    week_number=None   # Kalenderwoche (Optional, None wenn nicht benötigt)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kapitel: Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Durchschnittliche Verspätung in Minuten nach Zugart und Bahnhof berechnen\n",
    "average_min_delay_data = calculate_average_min_delay_by_category_and_station_x(\n",
    "    data=arrival_filtered_data,\n",
    "    delay_threshold=5,  # Schwellenwert in Minuten\n",
    "    categories=None,\n",
    "    combine_all_categories=False\n",
    ")\n",
    "#print(average_min_delay_data)\n",
    "#format_and_save_to_csv(average_min_delay_data, [\"Zugart\", \"Bahnhof\", \"Durchschnittliche Verspätung (in min)\"], \"Arrival_average_min_delay_by_category_and_station.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. arrival_percentage_delay_by_categorie_more_than_5.png\n",
    "percentage_delay_data = calculate_percentage_delay_by_category_and_station_x(\n",
    "    data=arrival_filtered_data,\n",
    "    delay_threshold=5,  # Schwellenwert in Minuten\n",
    "    categories=[\"IC\", \"ICE\", \"RB\", \"RE\", \"S\", \"TGV\", \"VIA\", \"HLB\", \"N\", \"NJ\", \"FLX\", \"ECE\"],\n",
    "    combine_all_categories=False\n",
    ")\n",
    "plot_bar_chart_by_category_and_station_x(\n",
    "        data=percentage_delay_data,\n",
    "        title='Prozentuale Verspätung ankommender Züge je Zugart pro Bahnhof (mehr als 5 Minuten)',\n",
    "        x_axis_label='Zugart',\n",
    "        y_axis_label='Anteil verpäteter Züge (%)',\n",
    "        fig_size_x=12,\n",
    "        fig_size_y=6,\n",
    "        int_value=True,        # Bei Prozentualen Ausfällen muss es hier \"False\" sein\n",
    "    )\n",
    "#create_csv_calculate_percentage_delay_by_category_and_station_x(percentage_delay_data, \"X.csv\")\n",
    "reorder_percentage_delay_data = reorder_calculate_percentage_delay_by_category_and_station_x(percentage_delay_data, \"-\")\n",
    "print(reorder_percentage_delay_data)\n",
    "create_csv(reorder_percentage_delay_data, \"out/01_Prozentuale Verspätung ankommender Züge je Zugart pro Bahnhof.csv\")\n",
    "ersetze_char_in_csv(\"out/01_Prozentuale Verspätung ankommender Züge je Zugart pro Bahnhof.csv\", \".\", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. depature_percentage_delay_by_categorie_more_than_5.png\n",
    "percentage_delay_data = calculate_percentage_delay_by_category_and_station_x(\n",
    "    data=depature_filtered_data,\n",
    "    delay_threshold=5,  # Schwellenwert in Minuten\n",
    "    categories=[\"IC\", \"ICE\", \"RB\", \"RE\", \"S\", \"TGV\", \"VIA\", \"HLB\", \"N\", \"NJ\", \"FLX\", \"ECE\"],\n",
    "    combine_all_categories=False\n",
    ")\n",
    "plot_bar_chart_by_category_and_station_x(\n",
    "        data=percentage_delay_data,\n",
    "        title='Prozentuale Verspätung abfahrender Züge je Zugart pro Bahnhof (mehr als 5 Minuten)',\n",
    "        x_axis_label='Zugart',\n",
    "        y_axis_label='Anteil verpäteter Züge (%)',\n",
    "        fig_size_x=12,\n",
    "        fig_size_y=6,\n",
    "        int_value=True,        # Bei Prozentualen Ausfällen muss es hier \"False\" sein\n",
    "    )\n",
    "#create_csv_calculate_percentage_delay_by_category_and_station_x(percentage_delay_data, \"X.csv\")\n",
    "reorder_percentage_delay_data = reorder_calculate_percentage_delay_by_category_and_station_x(percentage_delay_data, \"-\")\n",
    "print(reorder_percentage_delay_data)\n",
    "create_csv(reorder_percentage_delay_data, \"out/02_Prozentuale Verspätung abfahrender Züge je Zugart pro Bahnhof.csv\")\n",
    "ersetze_char_in_csv(\"out/02_Prozentuale Verspätung abfahrender Züge je Zugart pro Bahnhof.csv\", \".\", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Flex Ticket\n",
    "percentage_delay_data = calculate_percentage_delay_by_category_and_station_x(\n",
    "    data=depature_filtered_data,\n",
    "    delay_threshold=25,  # Schwellenwert in Minuten\n",
    "    categories=[\"IC\", \"ICE\", \"RB\", \"RE\", \"S\", \"TGV\", \"VIA\", \"HLB\", \"N\", \"NJ\", \"FLX\", \"ECE\"],\n",
    "    combine_all_categories=False\n",
    ")\n",
    "plot_bar_chart_by_category_and_station_x(\n",
    "        data=percentage_delay_data,\n",
    "        title='Anteil aufgehobener Zugverbindungen',\n",
    "        x_axis_label='Zugart',\n",
    "        y_axis_label='Anteil (%)',\n",
    "        fig_size_x=9,\n",
    "        fig_size_y=4,\n",
    "        int_value=True,        # Bei Prozentualen Ausfällen muss es hier \"False\" sein\n",
    "    )\n",
    "reorder_percentage_delay_data = reorder_calculate_percentage_delay_by_category_and_station_x(percentage_delay_data, \"-\")\n",
    "print(reorder_percentage_delay_data)\n",
    "create_csv(reorder_percentage_delay_data, \"out/03_Wahrscheinlichkeit zur Zugaufhebung.csv\")\n",
    "ersetze_char_in_csv(\"out/03_Wahrscheinlichkeit zur Zugaufhebung.csv\", \".\", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Verspätungsstatistik für eine Zugart berechnen\n",
    "ar_train_delay_data = calculate_delay_statistics_by_train_type_and_station_x(\n",
    "    data=arrival_filtered_data,\n",
    "    train_type=[\"IC\", \"ICE\", \"RB\", \"RE\", \"S\", \"TGV\", \"VIA\", \"HLB\", \"N\", \"NJ\", \"FLX\", \"ECE\"]     # Zugart (optional)\n",
    ")\n",
    "plot_bar_chart_by_category_and_station_x(\n",
    "        data=ar_train_delay_data,\n",
    "        title='Verspätungskategorien aller ankommenden Züge pro Bahnhof',\n",
    "        x_axis_label='Verspätungskategorie',\n",
    "        y_axis_label='Anteil verpäteter Züge (%)',\n",
    "        fig_size_x=12,\n",
    "        fig_size_y=4,\n",
    "        int_value=False,        # Bei Prozentualen Ausfällen muss es hier \"False\" sein\n",
    "    )\n",
    "\n",
    "dp_train_delay_data = calculate_delay_statistics_by_train_type_and_station_x(\n",
    "    data=depature_filtered_data,\n",
    "    train_type=[\"IC\", \"ICE\", \"RB\", \"RE\", \"S\", \"TGV\", \"VIA\", \"HLB\", \"N\", \"NJ\", \"FLX\", \"ECE\"]     # Zugart (optional)\n",
    ")\n",
    "plot_bar_chart_by_category_and_station_x(\n",
    "        data=dp_train_delay_data,\n",
    "        title='Verspätungskategorien aller abfahrenden Züge pro Bahnhof',\n",
    "        x_axis_label='Verspätungskategorie',\n",
    "        y_axis_label='Anteil verpäteter Züge (%)',\n",
    "        fig_size_x=12,\n",
    "        fig_size_y=4,\n",
    "        int_value=False,        # Bei Prozentualen Ausfällen muss es hier \"False\" sein\n",
    "    )\n",
    "ar_train_delay_data = reorder_calculate_delay_statistics_by_train_type_and_station_x(ar_train_delay_data, \"-\")\n",
    "dp_train_delay_data = reorder_calculate_delay_statistics_by_train_type_and_station_x(dp_train_delay_data, \"-\")\n",
    "create_csv(ar_train_delay_data, \"out/04_Verspätungskategorien aller ankommenden Züge pro Bahnhof.csv\")\n",
    "ersetze_char_in_csv(\"out/04_Verspätungskategorien aller ankommenden Züge pro Bahnhof.csv\", \".\", \",\")\n",
    "create_csv(dp_train_delay_data, \"out/05_Verspätungskategorien aller abfahrenden Züge pro Bahnhof.csv\")\n",
    "ersetze_char_in_csv(\"out/05_Verspätungskategorien aller abfahrenden Züge pro Bahnhof.csv\", \".\", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depature_cancellation_by_categorie\n",
    "result = calculate_cancellations_by_train_type_and_station(\n",
    "    data = depature_filtered_data,\n",
    "    train_types=[\"IC\", \"ICE\", \"RB\", \"RE\", \"S\", \"TGV\", \"VIA\", \"HLB\", \"N\", \"NJ\", \"FLX\", \"ECE\"],\n",
    "    calculate_percentage=True\n",
    ")\n",
    "plot_bar_chart_by_category_and_station_x(\n",
    "        data=result,\n",
    "        title='Anteil ausgefallener Züge (%)',\n",
    "        x_axis_label='Zugart',\n",
    "        y_axis_label='Ausfallanteil (%)',\n",
    "        fig_size_x=10,\n",
    "        fig_size_y=5,\n",
    "        int_value=True,        # Bei Prozentualen Ausfällen muss es hier \"False\" sein\n",
    "    )\n",
    "result = reorder_calculate_percentage_delay_by_category_and_station_x(result, \"-\")\n",
    "create_csv(result, \"out/06_Anteil ausgefallener Züge (%).csv\")\n",
    "ersetze_char_in_csv(\"out/06_Anteil ausgefallener Züge (%).csv\", \".\", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrival data\n",
    "cancellation_data_by_station = calculate_cancellations_by_operator_and_station(\n",
    "    depature_filtered_data,\n",
    "    operators=[\"DB Fernverkehr AG\", \"DB Regio AG\", \"Flixtrain\", \"Hessische Landesbahn\", \"VIAS GmbH\"],       # z. B. \"DB Fernverkehr AG\"\n",
    "    calculate_percentage=True\n",
    ")\n",
    "plot_bar_chart_by_category_and_station_x(\n",
    "        data=cancellation_data_by_station,\n",
    "        title='Ausfälle pro Betreiber',\n",
    "        x_axis_label='Betreiber',\n",
    "        y_axis_label='Anteiliger Zugausfall (%)',\n",
    "        fig_size_x=8,\n",
    "        fig_size_y=4,\n",
    "        int_value=False,        # Bei Prozentualen Ausfällen muss es hier \"False\" sein\n",
    "    )\n",
    "cancellation_data_by_station = reorder_calculate_cancellations_by_operator_and_station(cancellation_data_by_station, \"-\")\n",
    "create_csv(cancellation_data_by_station, \"out/07_Ausfälle pro Betreiber (%).csv\")\n",
    "ersetze_char_in_csv(\"out/07_Ausfälle pro Betreiber (%).csv\", \".\", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellation_data_by_operator_and_week = calculate_cancellations_by_operator_and_week(\n",
    "    data=arrival_filtered_data,\n",
    "    operator=None,\n",
    "    calculate_percentage=False\n",
    ")\n",
    "\n",
    "cancellation_data_by_week = calculate_cancellations_by_week(\n",
    "    data=arrival_filtered_data,\n",
    "    calculate_percentage=False\n",
    ")\n",
    "\n",
    "\n",
    "plot_data = None\n",
    "# 4. Balkendiagramm erstellen\n",
    "if plot_data is None:\n",
    "    print(\"\")\n",
    "elif plot_data is not cancellation_data_by_week:\n",
    "    plot_bar_chart_by_category_and_station_x(\n",
    "        data=plot_data,\n",
    "        title='Prozentuale Verspätung je Zugart pro Bahnhof (mehr als 5 Minuten)',\n",
    "        x_axis_label='Zugart',\n",
    "        y_axis_label='Anteil verpäteter Züge (%)',\n",
    "        fig_size_x=12,\n",
    "        fig_size_y=6,\n",
    "        int_value=True,        # Bei Prozentualen Ausfällen muss es hier \"False\" sein\n",
    "    )\n",
    "elif plot_data is cancellation_data_by_week:\n",
    "    plot_cancellations_by_week(\n",
    "        data=plot_data,\n",
    "        title='Ausfälle je Kalenderwoche',\n",
    "        x_axis_label='Kalenderwoche',\n",
    "        y_axis_label='Anzahl Ausfälle',\n",
    "        fig_size_x=6,\n",
    "        fig_size_y=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wichtig: Depature Züge\n",
    "line = \"RE1\"\n",
    "\n",
    "delay_by_line_and_day = calculate_delay_by_line_and_day(\n",
    "    data=depature_filtered_data, \n",
    "    line=line, \n",
    "    output_type=\"min\", \n",
    "    delay_threshold=0\n",
    ")\n",
    "plot_line_chart(delay_by_line_and_day, title=\"Durchschnittliche Verspätung des RE1 (in Minuten)\", xlabel=\"Wochentag\", ylabel=\"Minuten\")\n",
    "delay_by_line_and_day = reorder_calculate_delay_by_line_and_day(delay_by_line_and_day)\n",
    "create_csv(delay_by_line_and_day, \"out/08_Durchschnittliche Verspätung des RE1 (in Minuten).csv\")\n",
    "ersetze_char_in_csv(\"out/08_Durchschnittliche Verspätung des RE1 (in Minuten).csv\", \".\", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"RE1\"\n",
    "\n",
    "cancelldation_by_line_and_day = calculate_cancellations_by_line_and_day(\n",
    "    depature_filtered_data, \n",
    "    line, \n",
    "    \"absolute\",\n",
    "    \"day_of_week\"\n",
    ")\n",
    "#plot_line_chart(cancelldation_by_line_and_day, title=\"Ausfälle des RE1\", xlabel=\"Wochentag\", ylabel=\"Anzahl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depature_cancellation_time_by_categorie_short-distance\n",
    "result = calculate_cancellation_statistics_by_train_type_and_station(\n",
    "    data = depature_filtered_data,\n",
    "    train_types=[\"RB\", \"RE\", \"S\", \"VIA\", \"HLB\", \"N\"]\n",
    ")\n",
    "plot_bar_chart_by_category_and_station_x(\n",
    "        data=result,\n",
    "        title='Zeitpunkt der Ausfallbekanntgabe für Nahverkehrszüge nach Kategorien',\n",
    "        x_axis_label='Kategorie',\n",
    "        y_axis_label='Ausfallanteil (%)',\n",
    "        fig_size_x=13,\n",
    "        fig_size_y=5,\n",
    "        int_value=False,        # Bei Prozentualen Ausfällen muss es hier \"False\" sein\n",
    "    )\n",
    "\n",
    "# Tabelle sortieren\n",
    "sorted_df = reorder_calculate_cancellation_statistics_by_train_type_and_station(result)\n",
    "create_csv(sorted_df, \"out/09_Zeitpunkt der Ausfallbekanntgabe für Nahverkehrszüge.csv\")\n",
    "ersetze_char_in_csv(\"out/09_Zeitpunkt der Ausfallbekanntgabe für Nahverkehrszüge.csv\", \".\", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depature_cancellation_time_by_categorie_long-distance\n",
    "result = calculate_cancellation_statistics_by_train_type_and_station(\n",
    "    data = depature_filtered_data,\n",
    "    train_types=[\"IC\", \"ICE\", \"TGV\", \"NJ\", \"FLX\", \"ECE\"]\n",
    ")\n",
    "plot_bar_chart_by_category_and_station_x(\n",
    "        data=result,\n",
    "        title='Zeitpunkt der Ausfallbekanntgabe für Fernverkehrszüge nach Kategorien',\n",
    "        x_axis_label='Kategorie',\n",
    "        y_axis_label='Ausfallanteil (%)',\n",
    "        fig_size_x=13,\n",
    "        fig_size_y=5,\n",
    "        int_value=False,        # Bei Prozentualen Ausfällen muss es hier \"False\" sein\n",
    "    )\n",
    "# Tabelle sortieren\n",
    "sorted_df = reorder_calculate_cancellation_statistics_by_train_type_and_station(result)\n",
    "create_csv(sorted_df, \"out/10_Zeitpunkt der Ausfallbekanntgabe für Fernverkehrszüge.csv\")\n",
    "ersetze_char_in_csv(\"out/10_Zeitpunkt der Ausfallbekanntgabe für Fernverkehrszüge.csv\", \".\", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the CSV files\n",
    "csv_directory = './out'  # Replace with your CSV directory path\n",
    "output_excel_file = './out/output.xlsx'  # Name of the output Excel file\n",
    "\n",
    "# Create a new Excel writer object\n",
    "with pd.ExcelWriter(output_excel_file, engine='openpyxl') as writer:\n",
    "    # Loop through all files in the directory\n",
    "    dir = os.listdir(csv_directory)\n",
    "    dir.sort()\n",
    "    for file_name in dir:\n",
    "        # Check if the file is a CSV\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(csv_directory, file_name)\n",
    "\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path, sep=';', decimal=',')\n",
    "\n",
    "\n",
    "            print(df)\n",
    "\n",
    "            # Use the file name (without extension) as the sheet name\n",
    "            sheet_name = file_name\n",
    "\n",
    "            # Write the DataFrame to a new sheet in the Excel file\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"All CSV files have been combined into {output_excel_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
